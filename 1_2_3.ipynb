{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715b5990",
   "metadata": {},
   "source": [
    "As we have seend during the course, we can reach more than 0.99 of test accuracy in a couple of minutes on a laptop on the MNIST dataset. However, in many machine learning applications, especially in embedded systems, there is a need to optimize the learning time and also the inference time.\n",
    "\n",
    "Look for the fastest possible way to reach a 0.97 test accuracy, on a given hardware of your choice. The hardware that you use may be the laptop of one of your group members (you can also compare two laptops). You need to briefly present the hardware used (type of processor, frequency, number of cores, etc).\n",
    "In that respect, tour objective is to work on the acceleration of learning (model training) and / or of the inference time, using any method that seems relevant.\n",
    "Please note that your objective is not to simply reach the target test accuracy.\n",
    "It is required that you explore at leat one method taken from a book or from a scientific article. You can find the book or the article yourself, or use one of the references presented during the course. For instance, part II of the Deep learning book (see pdf for link) contains many interesting discussions, but other sources are accepted as well. Any research is welcome, including research on libraries that are not as famous as pytorch or tensorflow, like jax.\n",
    "Here are some suggestions :\n",
    "- You can start from the architecture that we use in this example : see pdf for link.\n",
    "And then try other methods to accelerate the learning or inference time.\n",
    "- Try to isolate parameters to present and analyze results of code profiling in order to find speed bottlenecks. Pay attention to the fact that profiling GPUs or pytorch code might have specificities."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
