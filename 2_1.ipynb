{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0953007d",
   "metadata": {},
   "source": [
    "Mandatory (very important): Before any processing you must fulfil these two steps :\n",
    "- mandatory : present the basic information about the problem, in the followin format :\n",
    "    - Number of features\n",
    "    - Number of samples\n",
    "    - Name of the target variable and physical meaning, if not obvious\n",
    "- Present the dataset shortly in your own words (please do not copy a description from another resource) and link to the url where you downloaded it from. For instance it is very important to present the features of this dataset that are not obvious for someone that is not necessarily familiar with the dataset.\n",
    "- explain very explicitely what problem you are trying to solve, and in particular what quantity you are trying to predict, as a function of which features. If the quantity to predict is one of the columns of the dataset, name it explicitely. If relevant, discuss why solving this problem would be interesting or have a value for an industry.\n",
    "You are encouraged to compare several estimators / optimization procedures, from different points of view (scoring, training, time, etc). General guideline : as this course is dedicated to discovering and exploring some of the many principles of machine learning, rather than being a production-oriented course, you are encouraged to explore original and personal approaches. It is not a huge deal is the final scored are not outstanding, as long as you took the chance to explore a custom approach and learned new methods.\n",
    "Suggestion of steps :\n",
    "- Provide general analysis of the dataset, that studies its statistical proeprties, outliers, correlation matrices, or any other interesting analysis. discuss whether it is consistent with intuition or not (instead of for instance just showing a correlation matrix).\n",
    "- If relevant or necessary, preprocess the data, and to justify this preprocessing. You could compare the estimators obtained with and without preprocessing.\n",
    "- Discuss the relevant optimization details : cross validation, hyperparameters, etc\n",
    "Again, explicit conclusions are very important :\n",
    "- Provide an avluation or multiple evaluations of the obtained estimators, thanks to scoring of your choice.\n",
    "- Discuss the results obtained. Have we solved the problem with this model ? Could the model be actually used ? What precision can be expected with the model on unseen data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31315006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\aurelien\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\aurelien\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aurelien\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aurelien\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aurelien\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aurelien\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\aurelien\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\aurelien\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\aurelien\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aurelien\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8354f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting imports...\n",
      "Importing numpy...\n",
      "OK numpy 2.4.0 time: 0.053 s\n",
      "Importing pandas...\n",
      "OK pandas 2.3.3 time: 0.272 s\n",
      "Importing sklearn.model_selection...\n",
      "OK train_test_split time: 32.47 s\n",
      "Importing sklearn.metrics...\n",
      "OK metrics time: 32.471 s\n",
      "All imports OK. Total time: 32.471 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eba3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"mental_health_dataset.csv\"\n",
    "TARGET = \"mental_health_risk\"\n",
    "\n",
    "TEST_SIZE = 0.25\n",
    "RANDOM_STATE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8a8ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 13\n",
      "Number of samples: 10000\n",
      "Target variable: mental_health_risk\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "print(\"Number of features:\", df.shape[1] - 1)\n",
    "print(\"Number of samples:\", df.shape[0])\n",
    "print(\"Target variable:\", TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7144258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fit_transform(X_train):\n",
    "    X = X_train.copy()\n",
    "\n",
    "    num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    num_medians = {}\n",
    "    for c in num_cols:\n",
    "        col = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "        med = col.median()\n",
    "        med = float(med) if pd.notna(med) else 0.0\n",
    "        num_medians[c] = med\n",
    "        X[c] = col.fillna(med).astype(float)\n",
    "\n",
    "    cat_modes = {}\n",
    "    for c in cat_cols:\n",
    "        mode = X[c].astype(str).mode(dropna=True)\n",
    "        m = str(mode.iloc[0]) if len(mode) else \"\"\n",
    "        cat_modes[c] = m\n",
    "        X[c] = X[c].astype(str).fillna(m)\n",
    "\n",
    "    X_num = X[num_cols].astype(float)\n",
    "    X_cat = pd.get_dummies(X[cat_cols], dummy_na=False)\n",
    "\n",
    "    means, stds = {}, {}\n",
    "    for c in num_cols:\n",
    "        m = X_num[c].mean()\n",
    "        s = X_num[c].std(ddof=0)\n",
    "        if s == 0:\n",
    "            s = 1\n",
    "        means[c] = m\n",
    "        stds[c] = s\n",
    "        X_num[c] = (X_num[c] - m) / s\n",
    "\n",
    "    X_proc = pd.concat([X_num, X_cat], axis=1)\n",
    "\n",
    "    state = {\n",
    "        \"num_cols\": num_cols,\n",
    "        \"cat_cols\": cat_cols,\n",
    "        \"num_medians\": num_medians,\n",
    "        \"cat_modes\": cat_modes,\n",
    "        \"means\": means,\n",
    "        \"stds\": stds,\n",
    "        \"features\": X_proc.columns\n",
    "    }\n",
    "\n",
    "    return X_proc.to_numpy(dtype=np.float64), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb459ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transform(X_test, state):\n",
    "    X = X_test.copy()\n",
    "\n",
    "    for c in state[\"num_cols\"]:\n",
    "        col = pd.to_numeric(X[c], errors=\"coerce\").fillna(state[\"num_medians\"][c])\n",
    "        X[c] = (col - state[\"means\"][c]) / state[\"stds\"][c]\n",
    "\n",
    "    for c in state[\"cat_cols\"]:\n",
    "        X[c] = X[c].astype(str).fillna(state[\"cat_modes\"][c])\n",
    "\n",
    "    X_num = X[state[\"num_cols\"]].astype(float)\n",
    "    X_cat = pd.get_dummies(X[state[\"cat_cols\"]], dummy_na=False)\n",
    "\n",
    "    X_proc = pd.concat([X_num, X_cat], axis=1)\n",
    "    X_proc = X_proc.reindex(columns=state[\"features\"], fill_value=0)\n",
    "\n",
    "    return X_proc.to_numpy(dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea9ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(y_train, y_test):\n",
    "    classes = sorted(y_train.astype(str).unique())\n",
    "    mapping = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "    y_train_enc = y_train.astype(str).map(mapping).to_numpy()\n",
    "    y_test_enc = y_test.astype(str).map(mapping).to_numpy()\n",
    "\n",
    "    return y_train_enc, y_test_enc, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9127ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MACHINE_LEARNING_TEK5_MODEL:\n",
    "    def __init__(self, lr=0.15, epochs=1200, l2=1e-3, batch_size=512, seed=7):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.l2 = l2\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "\n",
    "    def _softmax(self, z):\n",
    "        z -= z.max(axis=1, keepdims=True)\n",
    "        e = np.exp(z)\n",
    "        return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        n, d = X.shape\n",
    "        k = y.max() + 1\n",
    "\n",
    "        self.W = rng.normal(0, 0.01, (d, k))\n",
    "        self.b = np.zeros((1, k))\n",
    "\n",
    "        Y = np.eye(k)[y]\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            idx = rng.permutation(n)\n",
    "            for i in range(0, n, self.batch_size):\n",
    "                xb = X[idx[i:i+self.batch_size]]\n",
    "                yb = Y[idx[i:i+self.batch_size]]\n",
    "\n",
    "                probs = self._softmax(xb @ self.W + self.b)\n",
    "                grad = (probs - yb) / xb.shape[0]\n",
    "\n",
    "                self.W -= self.lr * (xb.T @ grad + self.l2 * self.W)\n",
    "                self.b -= self.lr * grad.sum(axis=0, keepdims=True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self._softmax(X @ self.W + self.b), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d217a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "X_train, state = preprocess_fit_transform(X_train_df)\n",
    "X_test = preprocess_transform(X_test_df, state)\n",
    "\n",
    "y_train_enc, y_test_enc, class_names = encode_labels(y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3a8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MACHINE_LEARNING_TEK5_MODEL()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "model.fit(X_train, y_train_enc)\n",
    "train_time = time.perf_counter() - t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300845bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977\n",
      "Training time (s): 1.722\n",
      "Prediction time (s): 0.001\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 576    0   16]\n",
      " [   0  410   25]\n",
      " [   5   12 1456]]\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "y_pred = model.predict(X_test)\n",
    "pred_time = time.perf_counter() - t1\n",
    "\n",
    "acc = accuracy_score(y_test_enc, y_pred)\n",
    "cm = confusion_matrix(y_test_enc, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", round(acc, 3))\n",
    "print(\"Training time (s):\", round(train_time, 3))\n",
    "print(\"Prediction time (s):\", round(pred_time, 3))\n",
    "print()\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa82a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class metrics:\n",
      "High\n",
      "  Precision: 0.991\n",
      "  Recall: 0.973\n",
      "  Support: 592\n",
      "Low\n",
      "  Precision: 0.972\n",
      "  Recall: 0.943\n",
      "  Support: 435\n",
      "Medium\n",
      "  Precision: 0.973\n",
      "  Recall: 0.988\n",
      "  Support: 1473\n"
     ]
    }
   ],
   "source": [
    "print(\"Per-class metrics:\")\n",
    "for i, cls in enumerate(class_names):\n",
    "    tp = cm[i, i]\n",
    "    fp = cm[:, i].sum() - tp\n",
    "    fn = cm[i, :].sum() - tp\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "    support = cm[i, :].sum()\n",
    "\n",
    "    print(cls)\n",
    "    print(\"  Precision:\", round(precision, 3))\n",
    "    print(\"  Recall:\", round(recall, 3))\n",
    "    print(\"  Support:\", support)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
